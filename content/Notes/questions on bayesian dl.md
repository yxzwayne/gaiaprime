---
title: Questions on Bayesian DL
tags:
  - notes
---
Obvious question: how could such grave issue be missed for years? 
- Answer 1: with few exceptions BDL community was disconnected from relevance and from larger DL community (2015-2020): tiny models, no benchmarking, emphasis on methods not results
- Answer 2: goals/metrics of BDL are not clear (2015-2020): uncertainty? OOD?, better sample efficiency?, continual learning?
- Answer 3: Bayesian zeal and confirmation bias


Which answer do you have the most opinion about?
If I want to gain intuition so I can think about the general Bayesian Deep Learning more coherently, can you suggest a concrete problem to think about first?
One of my research project was to train VAE to generatively model protein sequences and see if they learn higher-order marginals as strongly as a Potts model. It doesn't, but I don't

one intuition for a "distribution" is that we can indeed 

one more reason, is that it often much more computationally intensive,
right now, what works is point wise mass,
want to know the degree of correlation of one thing to another, conventional bayesian cares about the distribution of parameters.
to know the posterior distribution, we need the prior, but nothing seems uninformed is actually uninformed.
confirmation bias is the result, not the cause
- there is a distinction between 


I forgot i have a bunch of action items w.r.t. the VAE experiment :sweat_smile: Here is what I picked out from your previous message:
- 
